---
title: "Statistical Learning Assignment 2"
author: "Michael J Jones"
date: "24/04/2015"
output: pdf_document
---

# Question 1
Define a Cox Proportional Hazard Model (M1) for the covariates: clinic, prison, dose.

***

```{r}
library(survival)
library(knitr)

load("addicts.rda")
attach(dat)

M1 <- coxph(formula = Surv(time = survt, event = status) ~ clinic + prison + dose)

summary(M1)
```

# Question 2
Perform a regression analysis for the model M1 and provide a discussion of the results. Remark: Follow the 
instructions given in Tutorial 8.

***

In our regression analysis, we're going to use binomial logistic regression. This model is useful when our 
dependent variable is restricted to the values 1 and 0. In our case, our dependent variable is whether a patient 
drops out a clinic or not. In our data, this is encoded as the value (1) if the patient drops out of the clinic and 
(0) if they do not. In other words, logistic regression is useful when our dependent variable is binary and our 
explanatory variables are either continuous or categorical.

To perform this a logistic regression in R, we must use the `stats::glm` function and ensure we use the 
`family = binomial()` argument.

```{r}
binary.linear.regression <- glm(status ~ clinic + prison + dose, family = binomial())
summary(binary.linear.regression)
```

<!--
Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  4.22797    0.78182   5.408 6.38e-08 ***
clinic      -1.54175    0.30493  -5.056 4.28e-07 ***
prison      -0.04155    0.29257  -0.142   0.8871    
dose        -0.02630    0.01048  -2.509   0.0121 *  
-->

Looking at the summary table above, we can observe the coefficients of the explanatory variables (also known as the 
predictor variables). The coefficients determine to what degree each of the explanatory variables contribute to the 
value of the dependent variables.

Firstly, considering the coefficient for which clinic the patient went to shows that the value is negatively correlated 
with whether a patient will drop out of a clinic. We can see that there are two clinics:

```{r}
unique(dat$clinic)
```

This model implies that *Clinic 1* is more likely to have patients dropping out than *Clinic 2*. We can actually verify 
this by looking at the data for Clinic 1 and Clinic 2:

```{r}
dat.clinic1 <- dat[dat$clinic == 1,]
dat.clinic2 <- dat[dat$clinic == 2,]

table(dat.clinic1$status)
table(dat.clinic2$status)
```

Clinic 1 has a much higher dropout rate than Clinic 2. We can also see that this coefficient has a highly significant 
p value of 4.28e-04, meaning that it we have a very strong case to refute the null hypothesis that clinic doesn't 
contribute to our outcome that a patient will drop out of a clinic.

The coefficient for whether a patient has been to *Prison* implies that there is a very small negative correlation between 
having been to prison and dropping out of a clinic. This implies that those which have been to prison have a marginally 
lower chance of dropping out of the clinic. However, when we look at the p value for this coefficient, we can see plainly 
that, given this sample, we are unable to refute the null hypothesis. In other words, it appears that having been in 
prison probably doesn't contribute to whether a patient is likely to drop out of a clinic or not.

Unlike clinic and prison, the *dose* of methadone given to a patient is interesting in that it is a continuous 
variable as opposed to being categorical. The correlation of the regression with dose is -0.02630, indicating that 
a higher dose is negatively correlated with a patient dropping out of the clinic.

In summary then, observing the results of our linear regression, we can say that it is highly likely that a patient's 
risk of dropping out decreased when they go to Clinic 1 instead of Clinic 2 and two and if they are prescribed a higher 
dosage of methadone. However, it is very unlikely that the risk of a patient dropping out of a clinic is affected given 
they have been to prison or not.

# Question 3

## Part A
Check the proportional hazard assumption of M1 and adjust the model if necessary

***

R provides a way for us to calculate the proportional hazard assumption using `cox.zph`. This function allows us to 
measure proportionality with regard to log(time).

```{r}
proportionality.test <- cox.zph(fit = M1, transform = "log")
knitr::kable(proportionality.test$table)
```

<!--
|       |        rho|      chisq|         p|
|:------|----------:|----------:|---------:|
|clinic | -0.2140030|  7.7056532| 0.0055048|
|prison | -0.0462436|  0.3218268| 0.5705119|
|dose   |  0.1260549|  2.1238151| 0.1450249|
|GLOBAL |         NA| 10.4499011| 0.0151046|
-->

In the first column of the results table, we can see `rho`, which is the Pearson product-moment correlation 
between the scaled Schoenfeld residual and log(time) for each covariate.

The other column of interest to us is the right-most p-value column which shows the p-value given a null hypothesis 
that the proportionality violation has been violated. In other words, if the p-value of this column is *less than* 0.05, 
then we must refute the null hypothesis and assume that this particular covariate does in fact violate the proportionality 
assumption.

The `GLOBAL` p-value shows that the whole model violates the proportionality assumption. To remedy this, we might remove 
the clinic explanatory variable from our model and re-run the cox.zph command.

```{r}
M1.improved <- coxph(formula = Surv(time = survt, event = status) ~ prison + dose)

proportionality.test.improved <- cox.zph(fit = M1.improved, transform = "log")
knitr::kable(proportionality.test.improved$table)
```

<!--
|       |        rho|    chisq|         p|
|:------|----------:|--------:|---------:|
|prison | -0.1225006| 2.213461| 0.1368115|
|dose   |  0.1074185| 1.401130| 0.2365345|
|GLOBAL |         NA| 3.526046| 0.1715255|
-->

As you can see from the results of removing the clinic variable from M1, all explanatory variables as well as the GLOBAL 
p-value no longer are small enough to refute the null hypothesis and thus, we can conclude that the model is unlikely to 
refute the proportionality model.

## Part B
Visualize and discuss the Schoenfeld residues for the covariates.

***

Cox's proportional hazards assumes that there is a constant relationship between dependent variables and the explanatory 
variable. This means that the hazard function for any two individuals at any time are proportional. If the model assumes 
this then we need to test this assumption.

### Kaplan-Meier curves
There are a number of methods for confirming that our model (M1) conforms to the *proportional hazards assumption*. A simple, 
graphical way for doing this is to plot Kaplan-Meier curves for the survival function of each explanatory variable against
survival time of individuals. If the lines cross for different values of our explanatory variables then it is most 
probable that the two are not proportional, thereby violating the proportional hazards assumption.

```{r}
library(GGally)

ggsurv(survfit(formula = Surv(time = survt, event = status) ~ clinic,
            data = dat))

ggsurv(survfit(formula = Surv(time = survt, event = status) ~ prison,
            data = dat))

ggsurv(survfit(formula = Surv(time = survt, event = status) ~ dose,
            data = dat))
```

The Kaplan-Meier curve method of testing the proportional hazards assumption is not well suited to small data 
data sets where, consequently, curves may overlap without the proportional hazards assumption having been violated.

We can also see that, where there an explanatory variable has a lot of categories or is continuous (such as with *survt*), 
the graph is particularly difficult to read.

<!-- Plot "logarithm of negative logarithm of estimated survivor function" (see notes) -->


